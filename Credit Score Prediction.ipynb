{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f14e73b-7fd0-415e-a580-f09045225438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the columns in the dataset\n",
      "\n",
      "Index(['cust_id', 'income', 'savings', 'debt', 'r_savings_income',\n",
      "       'r_debt_income', 'r_debt_savings', 't_clothing_12', 't_clothing_6',\n",
      "       'r_clothing', 'r_clothing_income', 'r_clothing_savings',\n",
      "       'r_clothing_debt', 't_education_12', 't_education_6', 'r_education',\n",
      "       'r_education_income', 'r_education_savings', 'r_education_debt',\n",
      "       't_entertainment_12', 't_entertainment_6', 'r_entertainment',\n",
      "       'r_entertainment_income', 'r_entertainment_savings',\n",
      "       'r_entertainment_debt', 't_fines_12', 't_fines_6', 'r_fines',\n",
      "       'r_fines_income', 'r_fines_savings', 'r_fines_debt', 't_gambling_12',\n",
      "       't_gambling_6', 'r_gambling', 'r_gambling_income', 'r_gambling_savings',\n",
      "       'r_gambling_debt', 't_groceries_12', 't_groceries_6', 'r_groceries',\n",
      "       'r_groceries_income', 'r_groceries_savings', 'r_groceries_debt',\n",
      "       't_health_12', 't_health_6', 'r_health', 'r_health_income',\n",
      "       'r_health_savings', 'r_health_debt', 't_housing_12', 't_housing_6',\n",
      "       'r_housing', 'r_housing_income', 'r_housing_savings', 'r_housing_debt',\n",
      "       't_tax_12', 't_tax_6', 'r_tax', 'r_tax_income', 'r_tax_savings',\n",
      "       'r_tax_debt', 't_travel_12', 't_travel_6', 'r_travel',\n",
      "       'r_travel_income', 'r_travel_savings', 'r_travel_debt',\n",
      "       't_utilities_12', 't_utilities_6', 'r_utilities', 'r_utilities_income',\n",
      "       'r_utilities_savings', 'r_utilities_debt', 't_expenditure_12',\n",
      "       't_expenditure_6', 'r_expenditure', 'r_expenditure_income',\n",
      "       'r_expenditure_savings', 'r_expenditure_debt', 'cat_gambling',\n",
      "       'cat_debt', 'cat_credit_card', 'cat_mortgage', 'cat_savings_account',\n",
      "       'cat_dependents', 'credit_score', 'default'],\n",
      "      dtype='object')\n",
      "\n",
      "The first five(5) rows in the dataset\n",
      "      cust_id  income  savings     debt  r_savings_income  r_debt_income  \\\n",
      "0  C02COQEVYU   33269        0   532304            0.0000        16.0000   \n",
      "1  C02OZKC0ZF   77158    91187   315648            1.1818         4.0909   \n",
      "2  C03FHP2D0A   30917    21642   534864            0.7000        17.3000   \n",
      "3  C03PVPPHOY   80657    64526   629125            0.8000         7.8000   \n",
      "4  C04J69MUX0  149971  1172498  2399531            7.8182        16.0000   \n",
      "\n",
      "   r_debt_savings  t_clothing_12  t_clothing_6  r_clothing  ...  \\\n",
      "0          1.2000           1889           945      0.5003  ...   \n",
      "1          3.4615           5818           111      0.0191  ...   \n",
      "2         24.7142           1157           860      0.7433  ...   \n",
      "3          9.7499           6857          3686      0.5376  ...   \n",
      "4          2.0465           1978           322      0.1628  ...   \n",
      "\n",
      "   r_expenditure_savings  r_expenditure_debt  cat_gambling  cat_debt  \\\n",
      "0                 0.0000              0.0625          High         1   \n",
      "1                 0.7692              0.2222            No         1   \n",
      "2                 1.4286              0.0578          High         1   \n",
      "3                 1.2500              0.1282          High         1   \n",
      "4                 0.1163              0.0568          High         1   \n",
      "\n",
      "   cat_credit_card  cat_mortgage  cat_savings_account  cat_dependents  \\\n",
      "0                0             0                    0               0   \n",
      "1                0             0                    1               0   \n",
      "2                0             0                    1               0   \n",
      "3                0             0                    1               0   \n",
      "4                1             1                    1               1   \n",
      "\n",
      "   credit_score  default  \n",
      "0           444        1  \n",
      "1           625        0  \n",
      "2           469        1  \n",
      "3           559        0  \n",
      "4           473        0  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "\n",
      "The Number of rows and columns in the dataset\n",
      "(1000, 87)\n",
      "\n",
      "The structure and datatype of the dataset\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 87 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   cust_id                  1000 non-null   object \n",
      " 1   income                   1000 non-null   int64  \n",
      " 2   savings                  1000 non-null   int64  \n",
      " 3   debt                     1000 non-null   int64  \n",
      " 4   r_savings_income         1000 non-null   float64\n",
      " 5   r_debt_income            1000 non-null   float64\n",
      " 6   r_debt_savings           1000 non-null   float64\n",
      " 7   t_clothing_12            1000 non-null   int64  \n",
      " 8   t_clothing_6             1000 non-null   int64  \n",
      " 9   r_clothing               1000 non-null   float64\n",
      " 10  r_clothing_income        1000 non-null   float64\n",
      " 11  r_clothing_savings       1000 non-null   float64\n",
      " 12  r_clothing_debt          1000 non-null   float64\n",
      " 13  t_education_12           1000 non-null   int64  \n",
      " 14  t_education_6            1000 non-null   int64  \n",
      " 15  r_education              1000 non-null   float64\n",
      " 16  r_education_income       1000 non-null   float64\n",
      " 17  r_education_savings      1000 non-null   float64\n",
      " 18  r_education_debt         1000 non-null   float64\n",
      " 19  t_entertainment_12       1000 non-null   int64  \n",
      " 20  t_entertainment_6        1000 non-null   int64  \n",
      " 21  r_entertainment          1000 non-null   float64\n",
      " 22  r_entertainment_income   1000 non-null   float64\n",
      " 23  r_entertainment_savings  1000 non-null   float64\n",
      " 24  r_entertainment_debt     1000 non-null   float64\n",
      " 25  t_fines_12               1000 non-null   int64  \n",
      " 26  t_fines_6                1000 non-null   int64  \n",
      " 27  r_fines                  1000 non-null   float64\n",
      " 28  r_fines_income           1000 non-null   float64\n",
      " 29  r_fines_savings          1000 non-null   float64\n",
      " 30  r_fines_debt             1000 non-null   float64\n",
      " 31  t_gambling_12            1000 non-null   int64  \n",
      " 32  t_gambling_6             1000 non-null   int64  \n",
      " 33  r_gambling               1000 non-null   float64\n",
      " 34  r_gambling_income        1000 non-null   float64\n",
      " 35  r_gambling_savings       1000 non-null   float64\n",
      " 36  r_gambling_debt          1000 non-null   float64\n",
      " 37  t_groceries_12           1000 non-null   int64  \n",
      " 38  t_groceries_6            1000 non-null   int64  \n",
      " 39  r_groceries              1000 non-null   float64\n",
      " 40  r_groceries_income       1000 non-null   float64\n",
      " 41  r_groceries_savings      1000 non-null   float64\n",
      " 42  r_groceries_debt         1000 non-null   float64\n",
      " 43  t_health_12              1000 non-null   int64  \n",
      " 44  t_health_6               1000 non-null   int64  \n",
      " 45  r_health                 1000 non-null   float64\n",
      " 46  r_health_income          1000 non-null   float64\n",
      " 47  r_health_savings         1000 non-null   float64\n",
      " 48  r_health_debt            1000 non-null   float64\n",
      " 49  t_housing_12             1000 non-null   int64  \n",
      " 50  t_housing_6              1000 non-null   int64  \n",
      " 51  r_housing                1000 non-null   float64\n",
      " 52  r_housing_income         1000 non-null   float64\n",
      " 53  r_housing_savings        1000 non-null   float64\n",
      " 54  r_housing_debt           1000 non-null   float64\n",
      " 55  t_tax_12                 1000 non-null   int64  \n",
      " 56  t_tax_6                  1000 non-null   int64  \n",
      " 57  r_tax                    1000 non-null   float64\n",
      " 58  r_tax_income             1000 non-null   float64\n",
      " 59  r_tax_savings            1000 non-null   float64\n",
      " 60  r_tax_debt               1000 non-null   float64\n",
      " 61  t_travel_12              1000 non-null   int64  \n",
      " 62  t_travel_6               1000 non-null   int64  \n",
      " 63  r_travel                 1000 non-null   float64\n",
      " 64  r_travel_income          1000 non-null   float64\n",
      " 65  r_travel_savings         1000 non-null   float64\n",
      " 66  r_travel_debt            1000 non-null   float64\n",
      " 67  t_utilities_12           1000 non-null   int64  \n",
      " 68  t_utilities_6            1000 non-null   int64  \n",
      " 69  r_utilities              1000 non-null   float64\n",
      " 70  r_utilities_income       1000 non-null   float64\n",
      " 71  r_utilities_savings      1000 non-null   float64\n",
      " 72  r_utilities_debt         1000 non-null   float64\n",
      " 73  t_expenditure_12         1000 non-null   int64  \n",
      " 74  t_expenditure_6          1000 non-null   int64  \n",
      " 75  r_expenditure            1000 non-null   float64\n",
      " 76  r_expenditure_income     1000 non-null   float64\n",
      " 77  r_expenditure_savings    1000 non-null   float64\n",
      " 78  r_expenditure_debt       1000 non-null   float64\n",
      " 79  cat_gambling             1000 non-null   object \n",
      " 80  cat_debt                 1000 non-null   int64  \n",
      " 81  cat_credit_card          1000 non-null   int64  \n",
      " 82  cat_mortgage             1000 non-null   int64  \n",
      " 83  cat_savings_account      1000 non-null   int64  \n",
      " 84  cat_dependents           1000 non-null   int64  \n",
      " 85  credit_score             1000 non-null   int64  \n",
      " 86  default                  1000 non-null   int64  \n",
      "dtypes: float64(51), int64(34), object(2)\n",
      "memory usage: 679.8+ KB\n",
      "None\n",
      "\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "There is no missing value detected\n",
      "\n",
      "There are 0 duplicated rows in the dataset\n",
      "\n",
      "The number of unique values in the variables\n",
      "cust_id                    1000\n",
      "income                      951\n",
      "savings                     992\n",
      "debt                        943\n",
      "r_savings_income            463\n",
      "r_debt_income               545\n",
      "r_debt_savings              840\n",
      "t_clothing_12               916\n",
      "t_clothing_6                848\n",
      "r_clothing                  927\n",
      "r_clothing_income           649\n",
      "r_clothing_savings          545\n",
      "r_clothing_debt             445\n",
      "t_education_12              383\n",
      "t_education_6               375\n",
      "r_education                 102\n",
      "r_education_income          365\n",
      "r_education_savings         324\n",
      "r_education_debt            234\n",
      "t_entertainment_12          934\n",
      "t_entertainment_6           932\n",
      "r_entertainment             462\n",
      "r_entertainment_income      854\n",
      "r_entertainment_savings     716\n",
      "r_entertainment_debt        632\n",
      "t_fines_12                   71\n",
      "t_fines_6                    48\n",
      "r_fines                     924\n",
      "r_fines_income               51\n",
      "r_fines_savings              45\n",
      "r_fines_debt                 24\n",
      "t_gambling_12               377\n",
      "t_gambling_6                361\n",
      "r_gambling                  770\n",
      "r_gambling_income           304\n",
      "r_gambling_savings          257\n",
      "r_gambling_debt             228\n",
      "t_groceries_12              986\n",
      "t_groceries_6               968\n",
      "r_groceries                 635\n",
      "r_groceries_income          841\n",
      "r_groceries_savings         712\n",
      "r_groceries_debt            615\n",
      "t_health_12                 912\n",
      "t_health_6                  847\n",
      "r_health                    903\n",
      "r_health_income             635\n",
      "r_health_savings            425\n",
      "r_health_debt               443\n",
      "t_housing_12                458\n",
      "t_housing_6                 454\n",
      "r_housing                    14\n",
      "r_housing_income            440\n",
      "r_housing_savings           392\n",
      "r_housing_debt              418\n",
      "t_tax_12                    691\n",
      "t_tax_6                     639\n",
      "r_tax                       257\n",
      "r_tax_income                431\n",
      "r_tax_savings               351\n",
      "r_tax_debt                  253\n",
      "t_travel_12                 790\n",
      "t_travel_6                  785\n",
      "r_travel                    909\n",
      "r_travel_income             722\n",
      "r_travel_savings            706\n",
      "r_travel_debt               658\n",
      "t_utilities_12              915\n",
      "t_utilities_6               877\n",
      "r_utilities                 102\n",
      "r_utilities_income          555\n",
      "r_utilities_savings         485\n",
      "r_utilities_debt            448\n",
      "t_expenditure_12            999\n",
      "t_expenditure_6             993\n",
      "r_expenditure               863\n",
      "r_expenditure_income         72\n",
      "r_expenditure_savings       210\n",
      "r_expenditure_debt          280\n",
      "cat_gambling                  3\n",
      "cat_debt                      2\n",
      "cat_credit_card               2\n",
      "cat_mortgage                  2\n",
      "cat_savings_account           2\n",
      "cat_dependents                2\n",
      "credit_score                259\n",
      "default                       2\n",
      "dtype: int64\n",
      "\n",
      "MODEL/ALGORITHM PERFOMANCE EVALUATION USING MEAN ABSOLUTE ERROR(MAE) AND MEAN ABSOLUTE PERCENTAGE ERROR(MAPE) METRICS:\n",
      "\n",
      "The MAE of the LR is 21.923448863816514\n",
      "The MAPE of the LR is 0.038092830894654754\n",
      "The MAE of the RF is 21.71572\n",
      "The MAPE of the RF is 0.03758936995299626\n",
      "The MAE of the TREE is 31.768\n",
      "The MAPE of the TREE is 0.05516460583304715\n",
      "The MAE of the KN is 34.7704\n",
      "The MAPE of the KN is 0.0625592983517145\n",
      "The MAE of the xgb is 23.353872192382813\n",
      "The MAPE of the xgb is 0.04035695470513771\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Spreadsheets\\credit_score.csv\")\n",
    "\n",
    "def config_data(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Configuring the columns in the dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data.columns = data.columns.str.strip()\n",
    "    data.columns = data.columns.str.lower()\n",
    "    return data\n",
    "df = config_data(df)\n",
    "\n",
    "\n",
    "\n",
    "def inspect(data):\n",
    "\n",
    "    \"\"\"\n",
    "    Inspecting the data checking for the shape, structure, missing value, duplicated rows and number of unique values in each of the fatures on the dataframe in the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"checking the columns in the dataset\")\n",
    "    print()\n",
    "    print(data.columns)\n",
    "\n",
    "    print()\n",
    "    print('The first five(5) rows in the dataset')\n",
    "    print(data.head(5))\n",
    "\n",
    "    print()\n",
    "    print(\"The Number of rows and columns in the dataset\")\n",
    "    print(data.shape)\n",
    "    print()\n",
    "\n",
    "    print('The structure and datatype of the dataset')\n",
    "   \n",
    "    print()\n",
    "    print(data.info())\n",
    "    print()\n",
    "\n",
    "    for value in data.isna().sum():\n",
    "        if value > 1:\n",
    "            print(f\"There are {value} detected\")\n",
    "        else:\n",
    "            print('There is no missing value detected')\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(f\"There are {data.duplicated().sum()} duplicated rows in the dataset\")\n",
    "\n",
    "    print()\n",
    "    print(f\"The number of unique values in the variables\")\n",
    "    print(data.nunique())\n",
    "inspect(df)\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "def split(data):\n",
    "\n",
    "    \"\"\"\n",
    "    Splitting the data into Independent variables and target variable \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x = data.drop(['credit_score','cust_id','cat_gambling'],axis=1)\n",
    "    y = data.credit_score\n",
    "    return x, y \n",
    "\n",
    "x, y = split(df)\n",
    "num_col = x.select_dtypes(include=['int','float']).columns,\n",
    "cat_col = x.select_dtypes(include=['object']).columns\n",
    "\n",
    "    \n",
    "def train(x,y):\n",
    "\n",
    "    \"\"\"\n",
    "    Using a supervised approach to train and test the sets for modeling \n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=42)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train,x_test,y_train,y_test = train(x,y)\n",
    "    \n",
    "\n",
    "\n",
    "def process(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Processing and transforming the dataset for modeling \n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "   \n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most frequent')),\n",
    "        ('scaler', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num_pipe', num_pipe, num_col),\n",
    "            ('cat_pipe', cat_pipe, cat_col)\n",
    "        ],\n",
    "        remainder = 'passthrough'\n",
    "    )\n",
    "    return transformer\n",
    "    \n",
    "processor = process(df)\n",
    "\n",
    "\n",
    "def models(a,b):\n",
    "\n",
    "    \"\"\"\n",
    "    Buidling an algorithm tp predict credit score of user\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "    \n",
    "    models = {\n",
    "        'LR': LinearRegression(),\n",
    "        'RF': RandomForestRegressor(),\n",
    "        'TREE': DecisionTreeRegressor(), \n",
    "        'KN': KNeighborsRegressor(),\n",
    "        'xgb': XGBRegressor()\n",
    "    }\n",
    "\n",
    "    print(\"MODEL/ALGORITHM PERFOMANCE EVALUATION USING MEAN ABSOLUTE ERROR(MAE) AND MEAN ABSOLUTE PERCENTAGE ERROR(MAPE) METRICS:\")\n",
    "    print()\n",
    "    for name, model in models.items():\n",
    "        prediction = model.fit(a,b).predict(x_test)\n",
    "        \n",
    "        print(f\"The MAE of the {name} is {mean_absolute_error(y_test, prediction)}\")\n",
    "        print(f\"The MAPE of the {name} is {mean_absolute_percentage_error(y_test, prediction)}\")\n",
    "        \n",
    "models(x_train, y_train)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d5868-4c4b-4f0a-8757-fca53d8e7ce3",
   "metadata": {},
   "source": [
    "# Project Report: Credit Score Prediction\r\n",
    "\r\n",
    "## Introduction\r\n",
    "\r\n",
    "This project aims to predict credit scores based on various financial and personal attributes of individuals. The dataset used for this project contains information on income, savings, debt, and other financial behaviors, along with categorical variables such as gambling habits, debt status, and credit card usage. The target variable is the credit score, which is a numerical value indicating an individual's creditworthiness.\r\n",
    "\r\n",
    "## Data Preparation\r\n",
    "\r\n",
    "The dataset was initially loaded from a CSV file located at `C:\\Users\\user\\Desktop\\Spreadsheets\\credit_score.csv`. The data was then processed to ensure consistency and readiness for analysis. The following steps were taken:\r\n",
    "\r\n",
    "1. **Column Renaming**: All column names were stripped of leading and trailing spaces and converted to lowercase to ensure uniformity and ease of reference.\r\n",
    "2. **Data Inspection**: The dataset was inspected to understand its structure, including the columns, the first five rows, the number of rows and columns, and the data types of each column.\r\n",
    "3. **Missing Value Check**: The dataset was checked for missing values. No missing values were detected across any of the columns.\r\n",
    "4. **Duplicate Rows Check**: The dataset was checked for duplicate rows. No duplicate rows were found.\r\n",
    "5. **Unique Values Count**: The number of unique values in each variable was counted to understand the diversity of the data.\r\n",
    "\r\n",
    "## Data Splitting\r\n",
    "\r\n",
    "The dataset was split into features (X) and the target variable (credit score, Y). The features included all columns except for 'credit_score', 'cust_id', and 'cat_gambling'. The target variable was the 'credit_score' column.\r\n",
    "\r\n",
    "## Data Preprocessing\r\n",
    "\r\n",
    "The data was preprocessed using a pipeline that included imputation and scaling for both numerical and categorical variables. The numerical variables were scaled using the StandardScaler, while the categorical variables were encoded using the OrdinalEncoder. The imputation strategy for numerical variables was the mean, and for categorical variables, the most frequent category was used.\r\n",
    "\r\n",
    "## Model Training\r\n",
    "\r\n",
    "The dataset was split into training and testing sets, with 75% of the data used for training and 25% for testing. The following models were evaluated for their performance in predicting credit scores:\r\n",
    "\r\n",
    "- Linear Regression (LR)\r\n",
    "- Random Forest Regressor (RF)\r\n",
    "- Decision Tree Regressor (TREE)\r\n",
    "- K-Nearest Neighbors Regressor (KN)\r\n",
    "- XGBoost Regressor (xgb)\r\n",
    "\r\n",
    "Each model was trained on the training set and evaluated on the testing set using Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) as performance metrics.\r\n",
    "\r\n",
    "## Results\r\n",
    "\r\n",
    "The performance of the models was evaluated based on the MAE and MAPE metrics. The results are as follows:\r\n",
    "\r\n",
    "- **Linear Regression (LR)**: MAE = 21.92, MAPE = 0.0381\r\n",
    "- **Random Forest Regressor (RF)**: MAE = 21.72, MAPE = 0.0376\r\n",
    "- **Decision Tree Regressor (TREE)**: MAE = 31.77, MAPE = 0.0552\r\n",
    "- **K-Nearest Neighbors Regressor (KN)**: MAE = 34.77, MAPE = 0.0626\r\n",
    "- **XGBoost Regressor (xgb)**: MAE = 23.35, MAPE = 0.0404\r\n",
    "\r\n",
    "## Conclusion\r\n",
    "\r\n",
    "The project successfully demonstrated the process of predicting credit scores using various machine learning models. The XGBoost Regressor showed the best performance in terms of both MAE and MAPE, indicating its effectiveness in predicting credit scores based on the given dataset. This model could be further refined and validated using additional data or through cross-validation techniques to improve its predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a673937-23e4-4e32-b699-c1b8e4ccf483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
